{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e8b3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "\n",
    "# Define what device we are using\n",
    "use_cuda=True\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "884a633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is a hack to get around \"User-agent\" limitations when downloading MNIST datasets\n",
    "#       see, https://github.com/pytorch/vision/issues/3497 for more information\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "# MNIST Test dataset and dataloader declaration\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])),\n",
    "        batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fabe17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet Model definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702d2cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the network\n",
    "model = Net().to(device)\n",
    "\n",
    "# Load the pretrained model\n",
    "pretrained_model = \"data/lenet_mnist_model.pth\"\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af11d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, alpha, data_grad):\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + alpha*data_grad.sign()\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9791756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bim_attack(data, target, epsilon, alpha):\n",
    "    N = int(min(epsilon + 4, 1.25*epsilon))\n",
    "    perturbed_image = data\n",
    "    \n",
    "    for i in range(N):\n",
    "        data.requires_grad = True\n",
    "\n",
    "        output = model(data)\n",
    "        if output.max(1, keepdim=True)[1].item() != target.item(): continue # only test on correctly predicted data\n",
    "            \n",
    "        loss = F.nll_loss(output, target)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        data_grad = data.grad.data\n",
    "        perturbed_image = fgsm_attack(perturbed_image, alpha, data_grad)\n",
    "    \n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aded5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, device, test_loader, epsilon, alpha ):\n",
    "\n",
    "    # Accuracy counter\n",
    "    top1_correct = 0\n",
    "    top5_correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = bim_attack(data, target, epsilon, alpha)\n",
    "        \n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        \n",
    "        final_pred_top1 = torch.topk(output, 1).indices # get the index of the max log-probability\n",
    "        final_pred_top5 = torch.topk(output, 5).indices # get the index of the max log-probability\n",
    "        \n",
    "        if final_pred_top1.item() == target.item():\n",
    "            top1_correct += 1\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (final_pred_top1.item(), adv_ex) )\n",
    "        \n",
    "        \n",
    "        if target.item() in final_pred_top5:\n",
    "            top5_correct += 1\n",
    "        \n",
    "    # Calculate final accuracy for this epsilon\n",
    "    top1_accuracy = top1_correct/float(len(test_loader))\n",
    "    top5_accuracy = top5_correct/float(len(test_loader))\n",
    "    \n",
    "    # Return the accuracy and an adversarial example\n",
    "    return top1_accuracy, top5_accuracy, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b12743e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eps \u001b[38;5;129;01min\u001b[39;00m epsilons:\n\u001b[0;32m      8\u001b[0m     top1_accuracy, top5_accuracy, ex \u001b[38;5;241m=\u001b[39m test(model, device, test_loader, eps, alpha)\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mtop1_accuracy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(acc1)\n\u001b[0;32m     10\u001b[0m     top5_accuracy\u001b[38;5;241m.\u001b[39mappend(acc5)\n\u001b[0;32m     11\u001b[0m     examples\u001b[38;5;241m.\u001b[39mappend(ex)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "top1_accuracy = []\n",
    "top5_accuracy = []\n",
    "examples = []\n",
    "epsilons = [1, 2, 4, 8, 16]\n",
    "alpha = 0.1\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    top1_accuracy, top5_accuracy, ex = test(model, device, test_loader, eps, alpha)\n",
    "    top1_accuracy.append(acc1)\n",
    "    top5_accuracy.append(acc5)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons, top1_accuracy, \"*-\", label=\"Top-1\")\n",
    "plt.plot(epsilons, top5_accuracy, \"*-\", label=\"Top-5\")\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3bf80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
