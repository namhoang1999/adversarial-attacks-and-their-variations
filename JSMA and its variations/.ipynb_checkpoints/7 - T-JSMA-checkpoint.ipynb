{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f729d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "%run pretrained-model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a0a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd.functional import jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2085c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsma_jacobian(model, X):\n",
    "    f = lambda image: model(image).to(device)\n",
    "    \n",
    "    # output shape 10 x 784\n",
    "    return jacobian(f, X).squeeze().reshape(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "133b0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_map(jacobian, target, increasing, search_space, probability, image):\n",
    "    \"\"\"Compute saliency map of an image\n",
    "\n",
    "    jacobian:     The jacobian matrix\n",
    "    target:       The target label\n",
    "    increasing:   Denote the use of incrementing or decrementing pixels method\n",
    "    search_space: The image search space \n",
    "    probability:  The probability predicted by the model of all classes\n",
    "    image:        The input image X\n",
    "    \n",
    "    return:       The saliency map\n",
    "    \"\"\" \n",
    "    # add the Taylor term to all classes but the target class\n",
    "    probability[0, target] = 1\n",
    "    taylor = 1 - image if increasing else image\n",
    "    jacobian *= probability.reshape(10,1) * taylor \n",
    "    \n",
    "    # The forward derivative of the target class\n",
    "    target_grad = jacobian[target]  \n",
    "    # The sum of forward derivative of all other classes\n",
    "    others_grad = torch.sum(jacobian, dim=0) - target_grad  \n",
    "    \n",
    "    # Crossout pixels not in the search space\n",
    "    target_grad *= search_space \n",
    "    others_grad *= search_space\n",
    "\n",
    "    # Calculate sum of target forward derivative of any 2 features.\n",
    "    alpha = target_grad.reshape(-1, 1, 784) + target_grad.reshape(-1, 784, 1)  \n",
    "    # Calculate sum of other forward derivative of any 2 features.\n",
    "    beta = others_grad.reshape(-1, 1, 784) + others_grad.reshape(-1, 784, 1)\n",
    "\n",
    "    # Cross out entries that does not satisfy the condition (from formula 8 and 9)\n",
    "    condition1 = alpha > 0.0 if increasing else alpha < 0.0\n",
    "    condition2 = beta < 0.0 if increasing else beta > 0.0\n",
    "    zero_mask = torch.ones(784, 784).fill_diagonal_(0).to(device)\n",
    "\n",
    "    # Apply the condition to the saliency map\n",
    "    mask = (condition1 * condition2) * zero_mask\n",
    "    \n",
    "    # Form the actuall map, entries are either invalid (crossed out) or equal alpha x beta\n",
    "    saliency_map = alpha * torch.abs(beta) if increasing else torch.abs(alpha) * beta\n",
    "    saliency_map *= mask # cross out invalid entries\n",
    "    \n",
    "    # get the two most significant pixels\n",
    "    _, idx = torch.max(saliency_map.reshape(-1, 784 * 784), dim=1)\n",
    "    \n",
    "    p1 = torch.div(idx, 784, rounding_mode='floor')\n",
    "    p2 = idx % 784\n",
    "    \n",
    "    return p1.item(), p2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "246ef754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsma(image, target, step_size, max_iters, model):\n",
    "    \"\"\"Perform JSMA attack on an image\n",
    "\n",
    "    image:     The input image X\n",
    "    target:    The target label\n",
    "    step_size: The perturbation size\n",
    "    max_iters: The maximum itrations of the attack\n",
    "    model:     The prediction model\n",
    "    \n",
    "    return:    The adversatial image X*\n",
    "    \"\"\" \n",
    "        \n",
    "    shape = image.shape\n",
    "    image = torch.flatten(image) # Flatten the image to 1D for easier modification \n",
    "    \n",
    "    increasing    = True if step_size > 0 else False\n",
    "    search_domain = image < 1 if increasing else image > 0\n",
    "    \n",
    "    # Label predicted by the model\n",
    "    probability = model(image.reshape(shape))\n",
    "    prediction = torch.argmax(probability).item()\n",
    "\n",
    "    iter_ = 0\n",
    "    while (iter_ < max_iters) and (prediction != target) and (search_domain.sum() != 0):\n",
    "        # Calculate Jacobian matrix \n",
    "        jacobian = jsma_jacobian(model, image.reshape(shape))\n",
    "        # Get the two most salient pixels\n",
    "        p1, p2 = saliency_map(jacobian, target, increasing, search_domain, probability, image)\n",
    "        \n",
    "        # Modify pixels, and clip the image\n",
    "        image[p1] += step_size\n",
    "        image[p2] += step_size\n",
    "        image = torch.clamp(image, min=0.0, max=1.0)\n",
    "        \n",
    "        # Cross out modified pixels in the search space\n",
    "        search_domain[p1] = 0\n",
    "        search_domain[p2] = 0\n",
    "        \n",
    "        # Update the new label predicted by the model\n",
    "        probability = model(image.reshape(shape))\n",
    "        prediction = torch.argmax(probability).item()\n",
    "\n",
    "        iter_ += 1\n",
    "\n",
    "    return image.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7331323",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m test_loader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(test_loader)\n\u001b[0;32m      2\u001b[0m input1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(test_loader_iter)\n\u001b[1;32m----> 4\u001b[0m adv_image \u001b[38;5;241m=\u001b[39m \u001b[43mjsma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(torch\u001b[38;5;241m.\u001b[39margmax(model(adv_image)))\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mjsma\u001b[1;34m(image, target, step_size, max_iters, model)\u001b[0m\n\u001b[0;32m     26\u001b[0m jacobian \u001b[38;5;241m=\u001b[39m jsma_jacobian(model, image\u001b[38;5;241m.\u001b[39mreshape(shape))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Get the two most salient pixels\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m p1, p2 \u001b[38;5;241m=\u001b[39m \u001b[43msaliency_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjacobian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincreasing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_domain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Modify pixels, and clip the image\u001b[39;00m\n\u001b[0;32m     31\u001b[0m image[p1] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m step_size\n",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36msaliency_map\u001b[1;34m(jacobian, target, increasing, search_space, probability, image)\u001b[0m\n\u001b[0;32m     47\u001b[0m p1 \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m784\u001b[39m\n\u001b[0;32m     48\u001b[0m p2 \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m784\u001b[39m\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m(), p2\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "test_loader_iter = iter(test_loader)\n",
    "input1 = next(test_loader_iter)\n",
    "\n",
    "adv_image = jsma(image     = input1[0].to(device), \n",
    "                 target    = 3,  \n",
    "                 step_size = -1, \n",
    "                 max_iters = 40,\n",
    "                 model     = model).reshape([1,1,28,28])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(torch.argmax(model(adv_image)))\n",
    "plt.imshow(adv_image.squeeze().cpu(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4847ffa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 / 9 100.0\n",
      "18 / 18 100.0\n",
      "27 / 27 100.0\n",
      "36 / 36 100.0\n",
      "45 / 45 100.0\n",
      "54 / 54 100.0\n",
      "63 / 63 100.0\n",
      "72 / 72 100.0\n",
      "81 / 81 100.0\n",
      "90 / 90 100.0\n",
      "99 / 99 100.0\n",
      "108 / 108 100.0\n",
      "117 / 117 100.0\n",
      "126 / 126 100.0\n",
      "135 / 135 100.0\n",
      "144 / 144 100.0\n",
      "153 / 153 100.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;241m==\u001b[39m label\u001b[38;5;241m.\u001b[39mitem():\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m adv_image \u001b[38;5;241m=\u001b[39m \u001b[43mjsma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m])\n\u001b[0;32m     17\u001b[0m prediction \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(model(adv_image))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Correct if the prediction is the target label\u001b[39;00m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mjsma\u001b[1;34m(image, target, step_size, max_iters, model)\u001b[0m\n\u001b[0;32m     23\u001b[0m iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (iter_ \u001b[38;5;241m<\u001b[39m max_iters) \u001b[38;5;129;01mand\u001b[39;00m (prediction \u001b[38;5;241m!=\u001b[39m target) \u001b[38;5;129;01mand\u001b[39;00m (search_domain\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Calculate Jacobian matrix \u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     jacobian \u001b[38;5;241m=\u001b[39m \u001b[43mjsma_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Get the two most salient pixels\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     p1, p2 \u001b[38;5;241m=\u001b[39m saliency_map(jacobian, target, increasing, search_domain, probability, image)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mjsma_jacobian\u001b[1;34m(model, X)\u001b[0m\n\u001b[0;32m      2\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m image: model(image)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# output shape 10 x 784\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:670\u001b[0m, in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    668\u001b[0m jac_i: Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)))  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39mnelement()):\n\u001b[1;32m--> 670\u001b[0m     vj \u001b[38;5;241m=\u001b[39m \u001b[43m_autograd_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(jac_i, vj, inputs)):\n\u001b[0;32m    674\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vj_el \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py:159\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[1;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_grad_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:276\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for j in range(100):\n",
    "    image, label = next(test_loader_iter)\n",
    "    \n",
    "    for target in range(10):\n",
    "        # Can't target the actual label can we?\n",
    "        if target == label.item():\n",
    "            continue\n",
    "        \n",
    "        adv_image = jsma(image     = image.to(device), \n",
    "                         target    = target,  \n",
    "                         step_size = -1, \n",
    "                         max_iters = 40,\n",
    "                         model     = model).reshape([1,1,28,28])\n",
    "\n",
    "        prediction = torch.argmax(model(adv_image)).item()\n",
    "        \n",
    "        # Correct if the prediction is the target label\n",
    "        if prediction == target:\n",
    "            correct += 1\n",
    "    print(correct,'/', (j+1) * 9, correct * 100 / ((j+1) * 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f898382",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([1,2,3])\n",
    "b = torch.negative(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a8a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -a\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39bd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
