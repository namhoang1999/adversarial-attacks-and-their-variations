{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f729d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "%run pretrained-model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a0a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd.functional import jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2085c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsma_jacobian(model, X):\n",
    "    f = lambda image: model(image).to(device)\n",
    "    \n",
    "    # output shape 10 x 784\n",
    "    return jacobian(f, X).squeeze().reshape(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "133b0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_map(jacobian, target, increasing, search_space, probability):\n",
    "    \"\"\"Compute saliency map of an image\n",
    "\n",
    "    jacobian:     The jacobian matrix\n",
    "    target:       The target label\n",
    "    increasing:   Denote the use of incrementing or decrementing pixels method\n",
    "    search_space: The image search space \n",
    "    probability:  The probability predicted by the model of all classes\n",
    "    \n",
    "    return:       The saliency map\n",
    "    \"\"\" \n",
    "    \n",
    "    # add the weighted term to all classes but the target class\n",
    "    probability[0, target] = 1\n",
    "    jacobian *= probability.reshape(10,1)\n",
    "    \n",
    "    # The forward derivative of the target class\n",
    "    target_grad = jacobian[target]  \n",
    "    # The sum of forward derivative of all other classes\n",
    "    others_grad = torch.sum(jacobian, dim=0) - target_grad  \n",
    "    \n",
    "    # Crossout pixels not in the search space\n",
    "    target_grad *= search_space \n",
    "    others_grad *= search_space\n",
    "\n",
    "    # Calculate sum of target forward derivative of any 2 features.\n",
    "    alpha = target_grad.reshape(-1, 1, 784) + target_grad.reshape(-1, 784, 1)  \n",
    "    # Calculate sum of other forward derivative of any 2 features.\n",
    "    beta = others_grad.reshape(-1, 1, 784) + others_grad.reshape(-1, 784, 1)\n",
    "\n",
    "    # Cross out entries that does not satisfy the condition (from formula 8 and 9)\n",
    "    condition1 = alpha < 0.0 if increasing else alpha > 0.0\n",
    "    condition2 = beta > 0.0 if increasing else beta < 0.0\n",
    "    zero_mask = torch.ones(784, 784).fill_diagonal_(0).to(device)\n",
    "\n",
    "    # Apply the condition to the saliency map\n",
    "    mask = (condition1 * condition2) * zero_mask\n",
    "    \n",
    "    # Form the actuall map, entries are either invalid (crossed out) or equal alpha x beta\n",
    "    saliency_map = torch.abs(alpha) * beta if increasing else alpha * torch.abs(beta)\n",
    "    saliency_map *= mask # cross out invalid entries\n",
    "    \n",
    "    # get the two most significant pixels\n",
    "    _, idx = torch.max(saliency_map.reshape(-1, 784 * 784), dim=1)\n",
    "    \n",
    "    p1 = torch.div(idx, 784, rounding_mode='floor')\n",
    "    p2 = idx % 784\n",
    "    \n",
    "    return p1.item(), p2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246ef754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsma(image, label, step_size, max_iters, model):\n",
    "    \"\"\"Perform JSMA attack on an image\n",
    "\n",
    "    image:     The input image X\n",
    "    label:     The image label\n",
    "    step_size: The perturbation size\n",
    "    max_iters: The maximum itrations of the attack\n",
    "    model:     The prediction model\n",
    "    \n",
    "    return:    The adversatial image X*\n",
    "    \"\"\" \n",
    "        \n",
    "    shape = image.shape\n",
    "    image = torch.flatten(image) # Flatten the image to 1D for easier modification \n",
    "    \n",
    "    increasing    = True if step_size > 0 else False\n",
    "    search_domain = image < 1 if increasing else image > 0\n",
    "    \n",
    "    # Label predicted by the model\n",
    "    probability = model(image.reshape(shape))\n",
    "    prediction = torch.argmax(probability).item()\n",
    "\n",
    "    iter_ = 0\n",
    "    while (iter_ < max_iters) and (prediction == label) and (search_domain.sum() != 0):\n",
    "        # Calculate Jacobian matrix \n",
    "        jacobian = jsma_jacobian(model, image.reshape(shape))\n",
    "        # Get the two most salient pixels\n",
    "        p1, p2 = saliency_map(jacobian, label, increasing, search_domain, probability)\n",
    "        \n",
    "        # Modify pixels, and clip the image\n",
    "        image[p1] += step_size\n",
    "        image[p2] += step_size\n",
    "        image = torch.clamp(image, min=0.0, max=1.0)\n",
    "        \n",
    "        # Cross out modified pixels in the search space\n",
    "        search_domain[p1] = 0\n",
    "        search_domain[p2] = 0\n",
    "        \n",
    "        # Update the new label predicted by the model\n",
    "        probability = model(image.reshape(shape))\n",
    "        prediction = torch.argmax(probability).item()\n",
    "\n",
    "        iter_ += 1\n",
    "\n",
    "    return image.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7331323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19a0da79af0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loader_iter = iter(test_loader)\n",
    "input1 = next(test_loader_iter)\n",
    "print(device)\n",
    "adv_image = jsma(image     = input1[0].to(device), \n",
    "                 label     = input1[1].item(),  \n",
    "                 step_size = 1, \n",
    "                 max_iters = 40,\n",
    "                 model     = model).reshape([1,1,28,28])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(torch.argmax(model(adv_image)))\n",
    "plt.imshow(adv_image.squeeze().cpu(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4847ffa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 1 100.0\n",
      "2 / 2 100.0\n",
      "3 / 3 100.0\n",
      "4 / 4 100.0\n",
      "5 / 5 100.0\n",
      "6 / 6 100.0\n",
      "7 / 7 100.0\n",
      "8 / 8 100.0\n",
      "9 / 9 100.0\n",
      "10 / 10 100.0\n",
      "11 / 11 100.0\n",
      "12 / 12 100.0\n",
      "13 / 13 100.0\n",
      "14 / 14 100.0\n",
      "15 / 15 100.0\n",
      "16 / 16 100.0\n",
      "17 / 17 100.0\n",
      "18 / 18 100.0\n",
      "19 / 19 100.0\n",
      "20 / 20 100.0\n",
      "21 / 21 100.0\n",
      "22 / 22 100.0\n",
      "23 / 23 100.0\n",
      "24 / 24 100.0\n",
      "25 / 25 100.0\n",
      "26 / 26 100.0\n",
      "27 / 27 100.0\n",
      "28 / 28 100.0\n",
      "29 / 29 100.0\n",
      "30 / 30 100.0\n",
      "31 / 31 100.0\n",
      "32 / 32 100.0\n",
      "33 / 33 100.0\n",
      "34 / 34 100.0\n",
      "35 / 35 100.0\n",
      "36 / 36 100.0\n",
      "37 / 37 100.0\n",
      "38 / 38 100.0\n",
      "39 / 39 100.0\n",
      "40 / 40 100.0\n",
      "41 / 41 100.0\n",
      "42 / 42 100.0\n",
      "43 / 43 100.0\n",
      "44 / 44 100.0\n",
      "45 / 45 100.0\n",
      "46 / 46 100.0\n",
      "47 / 47 100.0\n",
      "48 / 48 100.0\n",
      "49 / 49 100.0\n",
      "50 / 50 100.0\n",
      "51 / 51 100.0\n",
      "52 / 52 100.0\n",
      "53 / 53 100.0\n",
      "54 / 54 100.0\n",
      "55 / 55 100.0\n",
      "56 / 56 100.0\n",
      "57 / 57 100.0\n",
      "58 / 58 100.0\n",
      "59 / 59 100.0\n",
      "60 / 60 100.0\n",
      "61 / 61 100.0\n",
      "62 / 62 100.0\n",
      "63 / 63 100.0\n",
      "64 / 64 100.0\n",
      "65 / 65 100.0\n",
      "66 / 66 100.0\n",
      "67 / 67 100.0\n",
      "68 / 68 100.0\n",
      "69 / 69 100.0\n",
      "70 / 70 100.0\n",
      "71 / 71 100.0\n",
      "72 / 72 100.0\n",
      "73 / 73 100.0\n",
      "74 / 74 100.0\n",
      "75 / 75 100.0\n",
      "76 / 76 100.0\n",
      "77 / 77 100.0\n",
      "78 / 79 98.73417721518987\n",
      "79 / 80 98.75\n",
      "80 / 81 98.76543209876543\n",
      "81 / 82 98.78048780487805\n",
      "82 / 83 98.79518072289157\n",
      "83 / 84 98.80952380952381\n",
      "84 / 85 98.82352941176471\n",
      "85 / 86 98.83720930232558\n",
      "86 / 87 98.85057471264368\n",
      "87 / 88 98.86363636363636\n",
      "88 / 89 98.87640449438203\n",
      "89 / 90 98.88888888888889\n",
      "90 / 91 98.9010989010989\n",
      "91 / 93 97.84946236559139\n",
      "92 / 94 97.87234042553192\n",
      "93 / 95 97.89473684210526\n",
      "94 / 96 97.91666666666667\n",
      "95 / 97 97.9381443298969\n",
      "96 / 98 97.95918367346938\n",
      "97 / 99 97.97979797979798\n",
      "98 / 100 98.0\n",
      "99 / 101 98.01980198019803\n",
      "100 / 102 98.03921568627452\n",
      "101 / 103 98.05825242718447\n",
      "102 / 104 98.07692307692308\n",
      "103 / 105 98.0952380952381\n",
      "104 / 106 98.11320754716981\n",
      "105 / 107 98.13084112149532\n",
      "106 / 108 98.14814814814815\n",
      "107 / 109 98.1651376146789\n",
      "108 / 110 98.18181818181819\n",
      "109 / 111 98.1981981981982\n",
      "110 / 112 98.21428571428571\n",
      "111 / 113 98.23008849557522\n",
      "112 / 114 98.24561403508773\n",
      "113 / 115 98.26086956521739\n",
      "114 / 116 98.27586206896552\n",
      "115 / 117 98.2905982905983\n",
      "116 / 118 98.30508474576271\n",
      "117 / 119 98.31932773109244\n",
      "118 / 120 98.33333333333333\n",
      "119 / 121 98.34710743801652\n",
      "120 / 122 98.36065573770492\n",
      "121 / 123 98.3739837398374\n",
      "122 / 124 98.38709677419355\n",
      "123 / 125 98.4\n",
      "124 / 126 98.41269841269842\n",
      "125 / 127 98.4251968503937\n",
      "126 / 128 98.4375\n",
      "127 / 129 98.44961240310077\n",
      "128 / 130 98.46153846153847\n",
      "129 / 131 98.47328244274809\n",
      "130 / 132 98.48484848484848\n",
      "131 / 133 98.49624060150376\n",
      "132 / 134 98.50746268656717\n",
      "133 / 135 98.51851851851852\n",
      "134 / 136 98.52941176470588\n",
      "135 / 137 98.54014598540147\n",
      "136 / 138 98.55072463768116\n",
      "137 / 139 98.56115107913669\n",
      "138 / 140 98.57142857142857\n",
      "139 / 141 98.58156028368795\n",
      "140 / 142 98.59154929577464\n",
      "141 / 143 98.6013986013986\n",
      "142 / 144 98.61111111111111\n",
      "143 / 145 98.62068965517241\n",
      "144 / 146 98.63013698630137\n",
      "145 / 147 98.63945578231292\n",
      "146 / 148 98.64864864864865\n",
      "147 / 149 98.65771812080537\n",
      "148 / 150 98.66666666666667\n",
      "149 / 151 98.67549668874172\n",
      "150 / 152 98.6842105263158\n",
      "151 / 153 98.69281045751634\n",
      "152 / 154 98.7012987012987\n",
      "153 / 155 98.70967741935483\n",
      "154 / 156 98.71794871794872\n",
      "155 / 157 98.72611464968153\n",
      "156 / 158 98.73417721518987\n",
      "157 / 159 98.74213836477988\n",
      "158 / 160 98.75\n",
      "159 / 161 98.75776397515529\n",
      "160 / 162 98.76543209876543\n",
      "161 / 163 98.77300613496932\n",
      "162 / 164 98.78048780487805\n",
      "163 / 165 98.78787878787878\n",
      "164 / 166 98.79518072289157\n",
      "165 / 167 98.80239520958084\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_prediction \u001b[38;5;241m!=\u001b[39m label:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m adv_image \u001b[38;5;241m=\u001b[39m \u001b[43mjsma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m])\n\u001b[0;32m     17\u001b[0m prediction \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(model(adv_image))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Correct if the prediction is the target label\u001b[39;00m\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mjsma\u001b[1;34m(image, label, step_size, max_iters, model)\u001b[0m\n\u001b[0;32m     26\u001b[0m jacobian \u001b[38;5;241m=\u001b[39m jsma_jacobian(model, image\u001b[38;5;241m.\u001b[39mreshape(shape))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Get the two most salient pixels\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m p1, p2 \u001b[38;5;241m=\u001b[39m \u001b[43msaliency_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjacobian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincreasing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_domain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobability\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Modify pixels, and clip the image\u001b[39;00m\n\u001b[0;32m     31\u001b[0m image[p1] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m step_size\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36msaliency_map\u001b[1;34m(jacobian, target, increasing, search_space, probability)\u001b[0m\n\u001b[0;32m     46\u001b[0m p1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiv(idx, \u001b[38;5;241m784\u001b[39m, rounding_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m p2 \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m784\u001b[39m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, p2\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for j in range(1000):\n",
    "    image, label = next(test_loader_iter)\n",
    "    \n",
    "    initial_prediction = torch.argmax(model(image.to(device))).item()\n",
    "    # Don't bother attacking if the image is already misclassified\n",
    "    if initial_prediction != label:\n",
    "        continue\n",
    "\n",
    "    adv_image = jsma(image     = image.to(device), \n",
    "                     label     = label,  \n",
    "                     step_size = 1, \n",
    "                     max_iters = 40,\n",
    "                     model     = model).reshape([1,1,28,28])\n",
    "\n",
    "    prediction = torch.argmax(model(adv_image)).item()\n",
    "\n",
    "    # Correct if the prediction is the target label\n",
    "    if prediction != label:\n",
    "        correct += 1\n",
    "    \n",
    "    print(correct, '/', j+1, correct * 100 / (j+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39bd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
